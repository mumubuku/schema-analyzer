# Schema Analyzer - AI 增强版使用指南

## 🎯 核心特性

### 混合策略：算法 + AI

针对 U8 数据库的特点，采用智能混合策略：

| 字段类型 | 识别方式 | 置信度 | 示例 |
|---------|---------|--------|------|
| **标准字段** | AI 直接识别 | 85-95% | `cDepCode`、`cInvCode`、`cPersonCode` |
| **自定义字段** | 关系推断 + AI | 60-80% | `cFree1-10`、`cDefine1-37` |
| **未知字段** | 纯关系推断 | 30-60% | 无关联的字段 |

## 🚀 快速开始

### 1. 获取阿里云 API Key

访问 [阿里云 DashScope](https://dashscope.console.aliyun.com/)：
1. 注册/登录阿里云账号
2. 开通 DashScope 服务（有免费额度）
3. 创建 API Key

### 2. 设置环境变量

```bash
export DASHSCOPE_API_KEY="sk-xxxxx"
```

### 3. 运行 AI 增强分析

```bash
# 构建
make build

# 分析 U8 数据库（启用 AI）
./schema-analyzer scan \
  --type sqlserver \
  --conn "server=localhost;user id=sa;password=pass;database=U8" \
  --output ./output \
  --enable-ai
```

## 📊 输出示例

### 标准字段（AI 直接识别）

```markdown
### Department（部门档案）

| 列名 | 中文名 | 类型 | 业务含义 | 来源 | 置信度 |
|------|--------|------|----------|------|--------|
| cDepCode | 部门编码 | varchar | 用于标识部门的唯一编码 | 🤖标准 | 95% |
| cDepName | 部门名称 | varchar | 部门的中文名称 | 🤖标准 | 95% |
| iDepGrade | 部门级次 | int | 部门在组织架构中的层级 | 🤖标准 | 90% |
```

### 自定义字段（AI 推断）

```markdown
| 列名 | 中文名 | 类型 | 业务含义 | 来源 | 置信度 |
|------|--------|------|----------|------|--------|
| cFree1 | 关联部门 | varchar | 基于与 Department.cDepCode 的关联推断 | 🔍推断 | 75% |
| cDefine1 | 项目编码 | varchar | 基于与 Project.cProjectCode 的关联推断 | 🔍推断 | 70% |
```

## 💡 工作原理

```
┌─────────────────────────────────────────────┐
│  1. 扫描数据库元数据                          │
│     - 表、列、索引、约束                      │
└─────────────────┬───────────────────────────┘
                  │
┌─────────────────▼───────────────────────────┐
│  2. 分类字段                                 │
│     ├─ 标准字段（cDepCode）→ AI 批量解释     │
│     └─ 自定义字段（cFree1）→ 先推断关系      │
└─────────────────┬───────────────────────────┘
                  │
┌─────────────────▼───────────────────────────┐
│  3. 推断关联关系（算法）                      │
│     - 命名相似度                             │
│     - 类型匹配                               │
│     - 值集合包含                             │
└─────────────────┬───────────────────────────┘
                  │
┌─────────────────▼───────────────────────────┐
│  4. AI 基于关联推断自定义字段                 │
│     - 输入：字段名 + 关联关系                 │
│     - 输出：中文名 + 业务含义                 │
└─────────────────┬───────────────────────────┘
                  │
┌─────────────────▼───────────────────────────┐
│  5. 生成增强版数据字典                        │
│     - Markdown（带 AI 解释）                 │
│     - JSON（完整数据）                       │
│     - Mermaid ER 图                         │
└─────────────────────────────────────────────┘
```

## 🔧 高级用法

### 直接传入 API Key

```bash
./schema-analyzer scan \
  --type sqlserver \
  --conn "..." \
  --enable-ai \
  --ai-key "sk-xxxxx"
```

### 只分析特定表

修改代码添加过滤（或后续版本支持）：

```go
WHERE TABLE_NAME IN ('Department', 'Inventory', 'Customer')
```

### 调整采样大小

```bash
--sample 5000  # 增加采样提高准确度
```

## 💰 成本估算

### 阿里云通义千问定价

- **qwen-turbo**: ¥0.008/千tokens（快速、便宜）
- **qwen-plus**: ¥0.02/千tokens（推荐）
- **qwen-max**: ¥0.12/千tokens（最准确）

### 典型场景

| 数据库规模 | 字段数 | Tokens | 成本（qwen-plus） |
|-----------|--------|--------|------------------|
| 小型（50表） | ~250 | ~25K | ~¥0.5 |
| 中型（100表） | ~500 | ~50K | ~¥1 |
| 大型（500表） | ~2500 | ~250K | ~¥5 |

**免费额度**：新用户通常有 100万 tokens 免费额度

## 🛡️ 隐私和安全

### 数据脱敏

AI 只接收：
- ✅ 表名、字段名
- ✅ 数据类型
- ✅ 统计摘要（null 率、唯一值率）

**不会发送**：
- ❌ 实际数据值
- ❌ 敏感业务数据
- ❌ 个人信息

### 示例

```json
{
  "table_name": "Employee",
  "column_name": "cDepCode",
  "data_type": "varchar(20)",
  "null_ratio": 0.05,
  "distinct_rate": 0.85
}
```

## 🔄 降级策略

AI 失败时自动降级：

```
🤖 AI 解释 500 个标准字段...
⚠️  AI 解释失败: API 超时，继续使用算法
✓ 使用关系推断生成字段说明
```

工具**始终可用**，即使：
- 没有 API Key
- API 调用失败
- 配额用尽

## 📖 完整文档

- [AI 集成详细指南](docs/AI_INTEGRATION.md)
- [架构设计](docs/ARCHITECTURE.md)
- [使用指南](docs/USAGE.md)

## 🎬 示例脚本

```bash
# 使用示例脚本
./examples/u8_ai_example.sh
```

## ❓ 常见问题

### Q: AI 识别不准确怎么办？

A: 
1. 检查关联关系是否正确（算法基础）
2. 增加采样大小 `--sample 5000`
3. 人工审核并修正重要字段

### Q: 可以用其他 AI 服务吗？

A: 可以！实现 `ai.Client` 接口即可：
- OpenAI GPT-4
- 本地 Ollama
- 其他 LLM 服务

### Q: 成本太高怎么办？

A:
1. 使用 qwen-turbo（更便宜）
2. 只对重要表启用 AI
3. 缓存结果避免重复调用

### Q: 担心数据安全？

A:
1. 使用本地 LLM（Ollama）
2. 只对非敏感字段启用 AI
3. 审查发送的数据（只有元数据）

## 🌟 最佳实践

1. **先运行不带 AI 的分析**
   ```bash
   ./schema-analyzer scan --type sqlserver --conn "..."
   ```

2. **查看关系推断结果**
   ```bash
   cat output/dict.md
   ```

3. **启用 AI 增强**
   ```bash
   ./schema-analyzer scan --type sqlserver --conn "..." --enable-ai
   ```

4. **人工审核重要表**
   - 核心业务表
   - 高频使用表
   - 关键字段

5. **导出为团队文档**
   ```bash
   cp output/dict.md docs/database-schema.md
   ```

## 🚀 下一步

- 尝试分析你的 U8 数据库
- 查看 AI 解释的准确度
- 提供反馈和建议
- 贡献代码改进

---

**提示**：首次使用建议先在测试环境试用，确认效果后再用于生产环境。
